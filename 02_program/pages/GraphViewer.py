# pages/GraphViewer.py
from __future__ import annotations
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import json, base64, textwrap

import numpy as np
import pandas as pd
import streamlit as st
import plotly.graph_objs as go
import streamlit.components.v1 as components
from string import Template

st.set_page_config(page_title="CSV Graph Viewer", layout="wide")
st.title("CSV Graph Viewerï¼‰")

# ========= Utils =========
@st.cache_data(show_spinner=False)
def _read_csv_cached(path: str) -> pd.DataFrame:
    p = Path(path)
    mtime = p.stat().st_mtime if p.exists() else 0.0
    _ = (path, mtime)  # cache key
    for enc in ("utf-8-sig", "cp932"):
        try:
            return pd.read_csv(p, encoding=enc)
        except Exception:
            continue
    return pd.read_csv(p)

def _common_columns(dfs: List[pd.DataFrame]) -> List[str]:
    cols = set(dfs[0].columns)
    for d in dfs[1:]:
        cols &= set(d.columns)
    return list(cols)

def _common_numeric_columns(dfs: List[pd.DataFrame], exclude: List[str]) -> List[str]:
    commons = [c for c in _common_columns(dfs) if c not in exclude]
    out = []
    for c in commons:
        ok = True
        for df in dfs:
            if pd.to_numeric(df[c], errors="coerce").notna().sum() == 0:
                ok = False; break
        if ok:
            out.append(c)
    return out

def _to_numeric_series(s: pd.Series) -> pd.Series:
    return pd.to_numeric(s, errors="coerce")

def _to_x_series(s: pd.Series) -> Tuple[pd.Series, str]:
    num = pd.to_numeric(s, errors="coerce")
    if num.notna().mean() > 0.8:
        return num, "numeric"
    dt = pd.to_datetime(s, errors="coerce", infer_datetime_format=True)
    if dt.notna().mean() > 0.8:
        return dt, "datetime"
    return s.astype(str), "category"

def _downsample_xy(x: pd.Series, y: pd.Series, max_points: int = 3000):
    n = len(x)
    if n <= max_points or max_points <= 0:
        return x, y
    step = int(np.ceil(n / max_points))
    return x.iloc[::step], y.iloc[::step]

def _get_saved_range_for(path: str):
    return st.session_state.get("graph_ranges", {}).get(path)

def _set_range_for(paths: List[str], x_col: str, kind: str, start, end):
    st.session_state.setdefault("graph_ranges", {})
    for p in paths:
        st.session_state["graph_ranges"][p] = {
            "x_col": x_col, "kind": kind,
            "start": pd.to_datetime(start).isoformat() if kind=="datetime" else float(start),
            "end":   pd.to_datetime(end).isoformat()   if kind=="datetime" else float(end),
        }

def _guess_mp4_value(row: Dict) -> Optional[str]:
    # åˆ—åã« mp4 / video ã‚’å«ã‚€åˆ—ã‚’å„ªå…ˆ
    for key in row.keys():
        if "mp4" in str(key).lower() or "video" in str(key).lower():
            v = str(row.get(key, "")).strip()
            if v:
                return v
    # å€¤ãŒ .mp4 ã§çµ‚ã‚ã‚‹ã‚‚ã®
    for _, v in row.items():
        s = str(v).strip()
        if s.lower().endswith(".mp4"):
            return s
    return None

def _resolve_media_path(value: str, data_dir: str) -> Path:
    p = Path(value)
    return p if p.is_absolute() else (Path(data_dir) / p).resolve()

@st.cache_data(show_spinner=False)
def _read_file_bytes(path: str) -> bytes:
    p = Path(path)
    _ = (str(p), p.stat().st_mtime if p.exists() else 0.0)  # cache key
    return p.read_bytes()

def _b64_data_url_mp4(p: Path) -> str:
    data = _read_file_bytes(str(p))
    b64 = base64.b64encode(data).decode("ascii")
    return f"data:video/mp4;base64,{b64}"

# ========= Home ã‹ã‚‰ã®é¸æŠ =========
records: List[Dict] | None = st.session_state.get("selected_records")
if not records:
    st.info("ãƒ¡ã‚¤ãƒ³ç”»é¢ï¼ˆHomeï¼‰ã§CSVã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    st.page_link("Home.py", label="â† ãƒ¡ã‚¤ãƒ³ã«æˆ»ã‚‹", icon="âª")
    st.stop()

labels: List[str] = []
path_map: Dict[str, str] = {}
rec_map: Dict[str, Dict] = {}
for i, rec in enumerate(records, start=1):
    row = rec.get("row", {})
    csv_path = rec.get("csv_path", "")
    name = row.get("name") or row.get("title") or Path(csv_path).name
    label = f"{i}. {name} ({Path(csv_path).name})"
    labels.append(label)
    path_map[label] = csv_path
    rec_map[label] = rec

# Home ã®æ—¢å®šé¸æŠã‚’åæ˜ 
default_labels = labels
sel_paths_state = st.session_state.get("selected_csv_paths")
if sel_paths_state:
    path_to_label = {v: k for k, v in path_map.items()}
    chosen = [path_to_label[p] for p in sel_paths_state if p in path_to_label]
    if chosen:
        default_labels = chosen

# ========= ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ =========
left, right = st.columns([1, 2], gap="large")

with left:
    st.subheader("ãƒ‡ãƒ¼ã‚¿ & è»¸ã®é¸æŠ")
    sel = st.multiselect("è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ï¼ˆè¤‡æ•°å¯ï¼‰", options=labels, default=default_labels)
    if not sel:
        st.warning("1ã¤ä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"); st.stop()

    dfs: List[pd.DataFrame] = []
    sel_paths: List[str] = []
    for lab in sel:
        p = path_map[lab]
        if not Path(p).exists():
            st.error(f"CSVãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {p}"); continue
        df = _read_csv_cached(p)
        if df is None or df.empty:
            st.warning(f"ç©ºã®CSVã®å¯èƒ½æ€§: {p}"); continue
        dfs.append(df); sel_paths.append(p)
    if not dfs:
        st.error("æœ‰åŠ¹ãªCSVãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚"); st.stop()

    common_cols = _common_columns(dfs)
    if not common_cols:
        st.error("é¸æŠã•ã‚ŒãŸCSVé–“ã«å…±é€šã™ã‚‹åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"); st.stop()

    x_default = "Time" if "Time" in common_cols else common_cols[0]
    x_col = st.selectbox("æ¨ªè»¸ (X)", options=sorted(common_cols), index=sorted(common_cols).index(x_default))

    y_candidates = _common_numeric_columns(dfs, exclude=[x_col])
    y_cols = st.multiselect(
        "ç¸¦è»¸ (Y)ï¼ˆå…±é€šã—ã¦æ•°å€¤å¤‰æ›ã§ãã‚‹åˆ—ï¼‰",
        options=sorted(y_candidates),
        default=[c for c in ["LFz", "RFz", "MTz"] if c in y_candidates] or (y_candidates[:1] if y_candidates else []))
    if not y_cols:
        st.warning("ç¸¦è»¸ (Y) ã‚’1ã¤ä»¥ä¸Šé¸æŠã—ã¦ãã ã•ã„ã€‚"); st.stop()

with right:
    # ======== å‹•ç”»ï¼‹ã‚°ãƒ©ãƒ•ï¼ˆåŒæœŸï¼‰ ========
    st.subheader("å‹•ç”» & ã‚°ãƒ©ãƒ•ï¼ˆå‹•ç”»ã®å†ç”Ÿä½ç½®ã«èµ¤ãƒ©ã‚¤ãƒ³ã‚’åŒæœŸï¼‰")

    # ã©ã®å‹•ç”»ã‚’ä½¿ã†ã‹ï¼ˆé¸æŠè¡Œã‹ã‚‰ mp4 æ¨å®šï¼‰
    video_labels: List[str] = []
    video_paths: Dict[str, Path] = {}
    for lab in sel:
        rec = rec_map[lab]
        row = rec.get("row", {})
        data_dir = rec.get("data_dir", "") or str(Path(__file__).parents[1] / "data")
        mp4_val = _guess_mp4_value(row)
        if not mp4_val:
            continue
        resolved = _resolve_media_path(mp4_val, data_dir)
        video_labels.append(lab)
        video_paths[lab] = resolved

    if not video_labels:
        st.info("é¸æŠã•ã‚ŒãŸè¡Œã« mp4 ã®åˆ—ï¼ˆã¾ãŸã¯ .mp4 ã®å€¤ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚Datalist ã® mp4 æ¬„ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        current_video_path: Optional[Path] = None
    else:
        lab_sel = st.selectbox("è¡¨ç¤ºã™ã‚‹å‹•ç”»ï¼ˆé¸æŠCSVã®ä¸­ã‹ã‚‰ï¼‰", options=video_labels)
        current_video_path = video_paths[lab_sel]
        if not current_video_path.exists():
            st.warning(f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: {current_video_path.as_posix()}")
            current_video_path = None

    # ===== å…¨ä½“ãƒ¬ãƒ³ã‚¸ =====
    x_series_first, x_kind = _to_x_series(dfs[0][x_col])
    x_min_all = x_series_first.min()
    x_max_all = x_series_first.max()

    # ===== ä¿å­˜æ¸ˆã¿ãƒ¬ãƒ³ã‚¸ï¼ˆä»£è¡¨ã¯å…ˆé ­ï¼‰ =====
    st.session_state.setdefault("graph_ranges", {})
    rep_path = sel_paths[0]
    saved = _get_saved_range_for(rep_path)

    if x_kind == "datetime":
        cur_start = pd.to_datetime(saved["start"]) if saved and saved.get("kind")=="datetime" else pd.to_datetime(x_min_all)
        cur_end   = pd.to_datetime(saved["end"])   if saved and saved.get("kind")=="datetime" else pd.to_datetime(x_max_all)
    else:
        x_min_f = float(pd.to_numeric(pd.Series([x_min_all]), errors="coerce").iloc[0])
        x_max_f = float(pd.to_numeric(pd.Series([x_max_all]), errors="coerce").iloc[0])
        if saved and saved.get("kind")=="numeric":
            cur_start, cur_end = float(saved["start"]), float(saved["end"])
        else:
            cur_start, cur_end = x_min_f, x_max_f

    # ===== ã‚°ãƒ©ãƒ•ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ï¼ˆJSã¸æ¸¡ã™ï¼‰ =====
    # Xã¯ã€Œå‹•ç”»0ç§’ï¼CSVæœ€å°Xã€ã«åˆã‚ã›ã‚‹ãŸã‚ã€JSå†…ã§ç§’ã«æ­£è¦åŒ–ã—ã¦ä½¿ã†
    x0_for_video = x_min_all  # å‹•ç”»0ç§’ã«ç›¸å½“ã™ã‚‹X
    traces = []
    for lab, df, p in zip(sel, dfs, sel_paths):
        x_raw = df[x_col]
        x_ser, _ = _to_x_series(x_raw)

        # è¡¨ç¤ºãƒ¬ãƒ³ã‚¸ã§æŠ½å‡º
        if x_kind == "datetime":
            x_dt = pd.to_datetime(x_ser)
            mask = (x_dt >= pd.to_datetime(cur_start)) & (x_dt <= pd.to_datetime(cur_end))
            x_in = x_dt[mask]
            x_sec = (pd.to_datetime(x_in) - pd.to_datetime(x0_for_video)).dt.total_seconds()
        else:
            x_num = pd.to_numeric(x_ser, errors="coerce")
            mask = (x_num >= float(cur_start)) & (x_num <= float(cur_end))
            x_in = x_num[mask]
            # æ•°å€¤ã¯ãã®ã¾ã¾ã€Œç§’ã€ã¨ã—ã¦æ‰±ã†
            x_sec = pd.to_numeric(x_in, errors="coerce")

        for yc in y_cols:
            y = _to_numeric_series(df[yc])[mask]
            x_plot, y_plot = _downsample_xy(x_sec, y, max_points=3000)
            traces.append({
                "name": f"{Path(p).name}:{yc}",
                "x": x_plot.astype(float).fillna(method="pad").fillna(0.0).tolist(),
                "y": pd.to_numeric(y_plot, errors="coerce").fillna(method="pad").fillna(0.0).tolist(),
            })

    # Xè»¸ã®åˆæœŸãƒ¬ãƒ³ã‚¸ï¼ˆç§’å˜ä½ï¼‰
    if x_kind == "datetime":
        init_x0 = float((pd.to_datetime(cur_start) - pd.to_datetime(x0_for_video)).total_seconds())
        init_x1 = float((pd.to_datetime(cur_end)   - pd.to_datetime(x0_for_video)).total_seconds())
    else:
        init_x0 = float(cur_start) - (float(x0_for_video) if isinstance(x0_for_video, (int,float,np.floating)) else 0.0)
        init_x1 = float(cur_end)   - (float(x0_for_video) if isinstance(x0_for_video, (int,float,np.floating)) else 0.0)

    # å‹•ç”»ãƒ‡ãƒ¼ã‚¿URLï¼ˆbytesâ†’base64ï¼‰
    video_data_url = _b64_data_url_mp4(current_video_path) if current_video_path else ""

    # ===== HTMLã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆvideo + plotlyï¼‰ =====
    traces_json = json.dumps(traces)

    html_template = Template("""
    <div style="display:flex; flex-direction:column; gap:10px; width:100%;">
    <video id="vid" controls style="width:100%; max-height:360px; background:#000;" src="$video_data_url"></video>
    <div id="chart" style="width:100%; height:520px;"></div>
    </div>
    <script src="https://cdn.plot.ly/plotly-2.30.0.min.js"></script>
    <script>
    const traces = $traces_json;
    const layout = {
        margin: {l: 35, r: 10, t: 10, b: 30},
        hovermode: "x unified",
        showlegend: true,
        xaxis: {
        title: "Time (s)",
        range: [$init_x0, $init_x1],
        showgrid: true
        },
        yaxis: {
        showgrid: true
        },
        shapes: [
        {
            type: 'line',
            x0: $init_x0, x1: $init_x0,
            y0: 0, y1: 1,
            xref: 'x', yref: 'paper',
            line: {color: 'red', width: 2}
        }
        ]
    };
    const data = traces.map(t => ({
        type: 'scattergl',
        mode: 'lines',
        name: t.name,
        x: t.x,
        y: t.y,
        line: {width: 2}
    }));
    const chart = document.getElementById('chart');
    Plotly.newPlot(chart, data, layout, {displaylogo:false, responsive:true});

    // å‹•ç”»ã®å†ç”Ÿä½ç½®ã§èµ¤ãƒ©ã‚¤ãƒ³ã‚’å‹•ã‹ã™ï¼ˆå‹•ç”»0ç§’ = Xè»¸0ç§’ï¼‰
    const vid = document.getElementById('vid');
    function updateVline(){
        const t = vid.currentTime || 0;  // ç§’
        Plotly.relayout(chart, {
        'shapes[0].x0': t,
        'shapes[0].x1': t
        });
    }
    vid.addEventListener('timeupdate', updateVline);
    vid.addEventListener('seeking', updateVline);
    vid.addEventListener('seeked', updateVline);
    vid.addEventListener('play', updateVline);

    // ã‚°ãƒ©ãƒ•ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ãŸä½ç½®ã«å‹•ç”»ã‚’ã‚¸ãƒ£ãƒ³ãƒ—ï¼ˆé€†åŒæœŸï¼‰
    chart.on('plotly_click', function(ev){
        if (!ev || !ev.points || !ev.points.length) return;
        const x = ev.points[0].x;
        try {
        vid.currentTime = Math.max(0, Number(x));
        updateVline();
        } catch(e) {}
    });
    </script>
    """)

    html = html_template.substitute(
        traces_json=traces_json,
        init_x0=str(init_x0),
        init_x1=str(init_x1),
        video_data_url=video_data_url
    )

    components.html(html, height=920, scrolling=False)

    # ===== ä¸‹ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰ï¼‹ å†æç”»ãƒœã‚¿ãƒ³ =====
    st.markdown("#### è§£æç¯„å›²ï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰â€” ãƒœã‚¿ãƒ³ã§ç¢ºå®šã—ã¦å†æç”»")
    if x_kind == "datetime":
        preview_start, preview_end = st.slider(
            "å¯¾è±¡åŒºé–“ï¼ˆæ—¥æ™‚ï¼‰",
            min_value=pd.to_datetime(x_min_all),
            max_value=pd.to_datetime(x_max_all),
            value=(pd.to_datetime(cur_start), pd.to_datetime(cur_end)),
            key=f"gv_preview_dt_{x_col}",
        )
        if st.button("å†æç”»ï¼ˆã“ã®ç¯„å›²ã‚’ç¢ºå®šï¼‰", type="primary"):
            _set_range_for(sel_paths, x_col, "datetime", preview_start, preview_end)
            st.rerun()
        st.caption(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¸­ï¼š{preview_start} ï½ {preview_end}")
    else:
        x_min_f = float(pd.to_numeric(pd.Series([x_min_all]), errors="coerce").iloc[0])
        x_max_f = float(pd.to_numeric(pd.Series([x_max_all]), errors="coerce").iloc[0])
        preview_start, preview_end = st.slider(
            "å¯¾è±¡åŒºé–“ï¼ˆæ•°å€¤ï¼‰",
            min_value=x_min_f, max_value=x_max_f,
            value=(float(cur_start), float(cur_end)),
            key=f"gv_preview_num_{x_col}",
        )
        if st.button("å†æç”»ï¼ˆã“ã®ç¯„å›²ã‚’ç¢ºå®šï¼‰", type="primary"):
            _set_range_for(sel_paths, x_col, "numeric", preview_start, preview_end)
            st.rerun()
        st.caption(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¸­ï¼š{preview_start:.3f} ï½ {preview_end:.3f}")

    st.page_link("pages/Report.py", label="â†’ ãƒ¬ãƒãƒ¼ãƒˆã‚’é–‹ãï¼ˆä¿å­˜æ¸ˆã¿ã®ç¯„å›²ãŒé€£å‹•ï¼‰", icon="ğŸ“„")
